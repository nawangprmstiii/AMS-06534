{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa7b162f",
   "metadata": {},
   "source": [
    "Nama : Nawang Pramesti Adji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb6152",
   "metadata": {},
   "source": [
    "NIM : A12.2020.06534"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c9386",
   "metadata": {},
   "source": [
    "Kelas : A12.6501"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82622fd",
   "metadata": {},
   "source": [
    "## Eksperimen dan Pengumpulan Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b331a",
   "metadata": {},
   "source": [
    "## Pemanggilan Library 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "459ca8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import tweepy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ceae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_config():\n",
    "    \"\"\"\n",
    "    Fungsi utilitas untuk mengkonfigurasi konsumsi file API Twitter dengan‚ê£\n",
    "    ,!kunci yang disediakan.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Autentikasi dan akses menggunakan keys\n",
    "    auth = tweepy.OAuthHandler(\"3WqiERQiyIS4bDs98zeMewIPU\", \n",
    "    \"i9Q4rRSAU1Ths8EDxpdCYcekyoHk98UW8DUKaKBgSMtNqoEBCX\")\n",
    "    auth.set_access_token(\"1576906033913417728-peMb29THb8tPCWayV9UDpb9hHEj7gD\", \n",
    "    \"CkytzLI8Pympc2zAwvjTj2pLIjis5IAdq1ATgJEe9sh6B\")\n",
    "    \n",
    "    # Kembalikan akses ke API\n",
    "    api = tweepy.API(auth)\n",
    "    try:\n",
    "        api.verify_credentials()\n",
    "        print(\"Authentication OK\")\n",
    "    except:\n",
    "        print(\"Error during authentication\")\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e26d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n"
     ]
    }
   ],
   "source": [
    "# Membuat extractor object\n",
    "extractor = twitter_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293d9132",
   "metadata": {},
   "source": [
    "## Ambil Tweet dari Username"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53634e38",
   "metadata": {},
   "source": [
    "Username yang saya ambil adalah @dsuperboy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98c6f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets terambil: 200.\n",
      "\n",
      "100 tweet teratas:\n",
      "\n",
      "@bellaksaragih dagang sate\n",
      "\n",
      "orang-orang terus jadi wibu https://t.co/sDzvfpIKM9\n",
      "\n",
      "orang-orang terus melupakan diri\n",
      "mereka sebelum mereka dilupakan\n",
      "kita masih keras hati saling melirik\n",
      "dalam jauh ja‚Ä¶ https://t.co/CpyQoDP9DO\n",
      "\n",
      "orang-orang terus jadi abu\n",
      "kita hanyut dalam waktu yang\n",
      "tidak pernah benar-benar kita\n",
      "miliki seusia pertemuan ini‚Ä¶ https://t.co/ymelkwmNxR\n",
      "\n",
      "cuma malam minggu. dah biasa.\n",
      "\n",
      "BERTEMU DI TEMARAM https://t.co/GkhFfvkOAc\n",
      "\n",
      "@berlianidris üòÖ\n",
      "\n",
      "Jangan ajari aku sabar. Dari kecil sampai sekarang aku belum pernah mandi bola.\n",
      "\n",
      "Di Twitter, cewek masak buat cowoknya, diributin. Cowok bawain tas ceweknya, diributin. Emang paling bener hidup di‚Ä¶ https://t.co/nOASLHrZsa\n",
      "\n",
      "Tak mengapa sendirian di sepanjang jalan. Mungkin sesekali sepi tapi pekerjaan demi pekerjaan semoga bisa mengobati‚Ä¶ https://t.co/Gz3eFs6ZiQ\n",
      "\n",
      "Jam-jam rawan mikir: buat apa ya gue buru mati-matian semua ini.\n",
      "\n",
      "@shadowwszx Lagi lapar, nggak bisa mikir. Met ultah ya\n",
      "\n",
      "Lapar mulu larut malam.\n",
      "\n",
      "Selamat tidur dari Siteba. https://t.co/EUCPnCzMRC\n",
      "\n",
      "Temukan tempat yang tepat untukmu. Sebab tidak di semua tempat ikan arwana bernilai tinggi.\n",
      "\n",
      "@mawardtl Iya\n",
      "\n",
      "Dinosaurusnya malah ikut ke rumah. https://t.co/9UR69KrFvs\n",
      "\n",
      "padahal sudah kutelan suaramu\n",
      "sebelum langkah-langkah menjauh\n",
      "sudah kurekam penuh tatap matamu\n",
      "sebelum udara memisa‚Ä¶ https://t.co/5QsgBggxek\n",
      "\n",
      "'biar kukirim kau ke bulan.'\n",
      "kemudian hari-hari penuh \n",
      "dengan daun-daun muda\n",
      "tumbuh bercabang di diriku\n",
      "\n",
      "kemudian h‚Ä¶ https://t.co/f7qqVPMBOl\n",
      "\n",
      "matahari kecil yang kau kirim \n",
      "setiap pagi di hadapan jendela\n",
      "alasan hari-hari harus dilalui\n",
      "dengan penuh gairah ya‚Ä¶ https://t.co/R8alms94uf\n",
      "\n",
      "Di antara masalah-masalah yang datang mencoba untuk melumpuhkan semangatku. Selalu kunyalakan api-api kecil dalam d‚Ä¶ https://t.co/LZhyvhQprq\n",
      "\n",
      "@Fajarrrx Bulan depan ya. Kumpulin struk belanja dulu\n",
      "\n",
      "Lumayan kokoh nih dinosaurus ü´° https://t.co/L5re1kxdLO\n",
      "\n",
      "Sekarang ada dinosaurus yang nemanin nulis buku di kopisop. https://t.co/4AOFhelM4m\n",
      "\n",
      "@karniforaa Beli kopinya dulu tiap hari selama sebulan. ü§£\n",
      "\n",
      "anakan dinosaurus. baru lahir, belum pandai pakai make up dan skinker. https://t.co/5mTW8SfiWN\n",
      "\n",
      "üòí: Tiap hari ke kopisop biar apa?\n",
      "\n",
      "Aku: Biar bisa bikin dinosaurus dari kertas struk belanja kopi. https://t.co/FdqEg1os6R\n",
      "\n",
      "Kuliahlah di Padang, setelah lulus kembali ke kotamu. Sebelum rindu membuatmu mencari-cari cara kembali ke kota ini.\n",
      "\n",
      "@waroyvhe Kamu agennya AC mbak Rara?\n",
      "\n",
      "Absen kota tempat tinggal warga di kolom komen.\n",
      "\n",
      "Dipikir orang main Twitter tinggal di pulau Jawa semua apa ya.\n",
      "\n",
      "Alhamdulillah, hari ini bangun agak pagian.\n",
      "\n",
      "ü§åüèª https://t.co/r8Ry9hwa7r\n",
      "\n",
      "üôèüèª https://t.co/Huc03qyYxy\n",
      "\n",
      "Bangsa kita memang bangsa yang bersih, makanya kita selalu disuguhi pemerintah yang rajin cuci tangan.\n",
      "\n",
      "Selain kopi, durian, dan yang asam-asam dan pedas. Kalau kamu asam lambung, sepertinya hal yang harus kamu hindari juga adalah berdebat.\n",
      "\n",
      "Setiap hari selalu ada sesuatu yang datang pada diri, yang harus kuhadapi. Meski kadang aku tidak sungguh-sungguh siap. :)\n",
      "\n",
      "@detikcom üò≠üò≠üò≠\n",
      "\n",
      "sebidang sawah\n",
      "menjelma tendangan\n",
      "menjelma gas air mata\n",
      "memupuk naluri menghabisi\n",
      "\n",
      "sebidang sawah\n",
      "seakan harus diga‚Ä¶ https://t.co/9NhXUTD5wx\n",
      "\n",
      "Jadi, target tahun ini udah progres berapa persen?\n",
      "\n",
      "@_yrom Gelap semua emang. Sampai ke konsep video videonya üòÖ\n",
      "\n",
      "@amirulasyie_ Oke Wqwq\n",
      "\n",
      "@amirulasyie_ Lah, ini kamu udah bangun.\n",
      "\n",
      "@Reza_pung Di mana salahnya bangun siang?\n",
      "\n",
      "Waktu sekolah jadi morning person kok.\n",
      "\n",
      "Kan belum ada sekolah sekte pemuda bangun siang. üòÖ\n",
      "\n",
      "Aku udah pernah bangun‚Ä¶ https://t.co/dT7FnG26De\n",
      "\n",
      "Saya bangun siang bukan karena malas, saya produktifnya sore hingga dinihari.\n",
      "\n",
      "@rrrrrruto Sorry lupa Wqwq ntar dijual deh ü§£\n",
      "\n",
      "@rrrrrruto Padahal bisa bikin sendiri wqq\n",
      "\n",
      "Harus gue yang jualan nih?\n",
      "\n",
      "Nggak banyak sih. Sejauh ini baru nerbitin 24 judul buku gegara hidup dengan pola sekte ini üòÖ https://t.co/p80goaztSc\n",
      "\n",
      "@rrrrrruto Mau beli nggak?\n",
      "\n",
      "Nggak telat bangun, kita beda cara menikmati hidup aja. https://t.co/rCoUhjlYD7\n",
      "\n",
      "pagi.\n",
      "\n",
      "Sebelum tidur, ingat, ada banyak hal yang membuatmu harus bertahan untuk terus hidup. Semisal, pas punya uang jangan lupa beli nasi Padang.\n",
      "\n",
      "Tidurlah. Pukul segini isi kepala emang kadang aneh-aneh. Malah main tebak-tebakan.\n",
      "\n",
      "Ayam-ayam apa yang enggak enak?\n",
      "\n",
      "beberapa puisi akhirnya kusimpan sendiri. aku tahu kau tak akan peduli semua yang kutulis. andai pun kau sadar itu‚Ä¶ https://t.co/rZh67XCqJR\n",
      "\n",
      "Beberapa orang membiarkan impiannya menggantung di tangan orang-orang yang tak bisa diharapkan. Terlalu takut berge‚Ä¶ https://t.co/iZgXtUVWsO\n",
      "\n",
      "Mungkin aku tidak dihitung di semesta yang luas ini. Hanya debu yang berterbangan. Jika pun aku hilang mungkin tak‚Ä¶ https://t.co/37IGztKVNl\n",
      "\n",
      "@koechengpondok Mati mah hal yang pasti üòÖ\n",
      "\n",
      "@ngapainsemangat Ini dalam banget emang\n",
      "\n",
      "@ainellim__ Ya bukan kematian lampu juga\n",
      "\n",
      "@masmas34b Emang lagu dia\n",
      "\n",
      "Kasih tahu judul lagu yang tema liriknya kematian dong.\n",
      "\n",
      "Dengar lagu bendera kuning di kopisop berasa mau nangis. Lemah.\n",
      "\n",
      "Lihat saja ketika kamu dapat masalah siapa yang selama ini kamu anggap kawan, malah ikut jatuhin kamu. Siapa yang jadi musuh dalam selimut.\n",
      "\n",
      "@Biruubiu ‚úäüèª\n",
      "\n",
      "@_puutttee Kalau banteng jadinya partai\n",
      "\n",
      "@Hambahagiana Tu udah dirantai ayamnya\n",
      "\n",
      "https://t.co/dGcAEg8myN\n",
      "\n",
      "Selamat pagi.\n",
      "\n",
      "Sesekali aku menghindar dari percakapan. Sesekali aku tidak ingin membalas chat WhatsApp. Sesekali aku tidak ingin‚Ä¶ https://t.co/U5bSoEe0Lh\n",
      "\n",
      "Sudah melihat peluang cuma malas berjuang.\n",
      "\n",
      "Maaf ya kalau kadang pas ngobrol aku jawab 'hah hoh' doang. Lagi banyak pikiran soalnya.\n",
      "\n",
      "aku membayangkan ada di sana\n",
      "di hamparan sabana liar yang hijau\n",
      "segerombol burung kecil berkejaran\n",
      "lalu menukik ke‚Ä¶ https://t.co/yPXdp3rmvU\n",
      "\n",
      "aku sering membayangkan ada di sana\n",
      "di atas sampan denganmu sembari menyapa\n",
      "riak-riak air yang berkejaran di sekita‚Ä¶ https://t.co/D6NwDTlNeh\n",
      "\n",
      "@zarryhendrik ü§£\n",
      "\n",
      "Yang tak bisa dihindari dari hidup; kawan-kawan seumuran akan pergi satu persatu mencari hidup mereka. Satu persatu‚Ä¶ https://t.co/bZF282nt14\n",
      "\n",
      "Adanya hantu jeruk nipis kak. https://t.co/kw0euuywcC\n",
      "\n",
      "@syauqijonnata_ Makasih rekomennya.\n",
      "\n",
      "Nggak gitu. Aku menemukan YouTube yang bahas hantu-hantuan banyak di pulau Jawa dan Kalimantan. Apakah orang di Sum‚Ä¶ https://t.co/U91ZibsaaY\n",
      "\n",
      "Ada akun youtube yang bahas hantu di Sumatera nggak sih?\n",
      "\n",
      "@menanammenuai Lai sabana e tu\n",
      "\n",
      "dikirim dari siteba yang hujan https://t.co/pgqcAmWMbT\n",
      "\n",
      "@Fourtrie Makasih rekomennya mas\n",
      "\n",
      "@Nfvxj 75 itu yang udah sampai ke pembaca. Kemarin stoknya 1000 (masih dalam pengiriman). Pantau aja ya.\n",
      "\n",
      "Di suatu hari defenisi hantu akan kita kenang bukan lagi sosok-sosok seram berdarah, tapi kerumunan berseragam yang haus darah.\n",
      "\n",
      "@arak_jahat Dm gopay\n",
      "\n",
      "@Androngehe Hantu yang menyemprotkan gas air mata\n",
      "\n",
      "@Gion29_Arzunt Ingat kata tukang parkir\n",
      "\n",
      "@arak_jahat Tips yang membantu\n",
      "\n",
      "@junayyy__ beli ya üòÖ\n",
      "\n",
      "Mau nulis novel horor tapi aku penakut ü´£\n",
      "\n",
      "@zarryhendrik Namanya juga divisi humas\n",
      "\n",
      "@KharismaHaris6 Langsung ke tkp\n",
      "\n",
      "untuk si paling overthinking https://t.co/q1vBHuJswD\n",
      "\n",
      "Rekomen dong akun YouTube yang hobinya bahas setan setan.\n",
      "\n",
      "@Adli_DHJ üôèüèª\n",
      "\n",
      "Selamat istirahat. https://t.co/CkpPE9RYRA\n",
      "\n",
      "Kapan kamu terakhir kali bertanya kabar pada dirimu sendiri? Apakah kamu masih menyempatkan diri untuk memberi hadi‚Ä¶ https://t.co/ET6bVoPEk2\n",
      "\n",
      "Kamu gimana kabarmu?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets = extractor.user_timeline(screen_name=\"dsuperboy\", count=1000)\n",
    "print(\"Tweets terambil: {}.\\n\".format(len(tweets)))\n",
    "\n",
    "print(\"100 tweet teratas:\\n\")\n",
    "for tweet in tweets[:100]:\n",
    "    print(tweet.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e71fce7",
   "metadata": {},
   "source": [
    "## Masukkan ke dalam dataframes Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f19b8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@bellaksaragih dagang sate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orang-orang terus jadi wibu https://t.co/sDzvf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orang-orang terus melupakan diri\\nmereka sebel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orang-orang terus jadi abu\\nkita hanyut dalam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cuma malam minggu. dah biasa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rekomen dong akun YouTube yang hobinya bahas s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>@Adli_DHJ üôèüèª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Selamat istirahat. https://t.co/CkpPE9RYRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kapan kamu terakhir kali bertanya kabar pada d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Kamu gimana kabarmu?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweets\n",
       "0                          @bellaksaragih dagang sate\n",
       "1   orang-orang terus jadi wibu https://t.co/sDzvf...\n",
       "2   orang-orang terus melupakan diri\\nmereka sebel...\n",
       "3   orang-orang terus jadi abu\\nkita hanyut dalam ...\n",
       "4                       cuma malam minggu. dah biasa.\n",
       "..                                                ...\n",
       "95  Rekomen dong akun YouTube yang hobinya bahas s...\n",
       "96                                       @Adli_DHJ üôèüèª\n",
       "97         Selamat istirahat. https://t.co/CkpPE9RYRA\n",
       "98  Kapan kamu terakhir kali bertanya kabar pada d...\n",
       "99                               Kamu gimana kabarmu?\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Membuat kerangka data menggunakan sintaks berikut\n",
    "dataset = pd.DataFrame(data = [tweet.text for tweet in tweets], columns = ['Tweets'])\n",
    "\n",
    "# Tampilan kerangka data\n",
    "display(dataset.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b499b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('dataset_dsuperboy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8737739",
   "metadata": {},
   "source": [
    "## Cleaning Word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f032ce",
   "metadata": {},
   "source": [
    "## Import Library untuk Cleaning Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c338c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fb6949",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45111c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@bellaksaragih dagang sate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>orang-orang terus jadi wibu https://t.co/sDzvf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>orang-orang terus melupakan diri\\nmereka sebel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>orang-orang terus jadi abu\\nkita hanyut dalam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cuma malam minggu. dah biasa.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Tweets\n",
       "0           0                         @bellaksaragih dagang sate\n",
       "1           1  orang-orang terus jadi wibu https://t.co/sDzvf...\n",
       "2           2  orang-orang terus melupakan diri\\nmereka sebel...\n",
       "3           3  orang-orang terus jadi abu\\nkita hanyut dalam ...\n",
       "4           4                      cuma malam minggu. dah biasa."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_dsuperboy.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516bba4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@bellaksaragih dagang sate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>orang-orang terus jadi wibu https://t.co/sDzvf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>orang-orang terus melupakan diri\\nmereka sebel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>orang-orang terus jadi abu\\nkita hanyut dalam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cuma malam minggu. dah biasa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>@cynrj Buku senandika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>https://t.co/qZAFp1K0sA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>Segala yang berlebihan itu nggak baik. Minum a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>Selamat istirahat diri sendiri.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>Instastori teman-temanku di konser semua.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             Tweets\n",
       "0             0                         @bellaksaragih dagang sate\n",
       "1             1  orang-orang terus jadi wibu https://t.co/sDzvf...\n",
       "2             2  orang-orang terus melupakan diri\\nmereka sebel...\n",
       "3             3  orang-orang terus jadi abu\\nkita hanyut dalam ...\n",
       "4             4                      cuma malam minggu. dah biasa.\n",
       "..          ...                                                ...\n",
       "195         195                              @cynrj Buku senandika\n",
       "196         196                            https://t.co/qZAFp1K0sA\n",
       "197         197  Segala yang berlebihan itu nggak baik. Minum a...\n",
       "198         198                    Selamat istirahat diri sendiri.\n",
       "199         199          Instastori teman-temanku di konser semua.\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77e90c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  200 non-null    int64 \n",
      " 1   Tweets      200 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a01acd",
   "metadata": {},
   "source": [
    "## Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0353df",
   "metadata": {},
   "source": [
    "Pertama lakukan instalasi modul ekphrasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f49a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ekphrasis in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (0.5.4)\n",
      "Requirement already satisfied: ujson in c:\\programdata\\anaconda3\\lib\\site-packages (from ekphrasis) (5.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from ekphrasis) (3.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from ekphrasis) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from ekphrasis) (0.4.4)\n",
      "Requirement already satisfied: ftfy in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from ekphrasis) (6.1.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from ekphrasis) (1.21.5)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from ekphrasis) (3.7)\n",
      "Requirement already satisfied: termcolor in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from ekphrasis) (2.0.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from ftfy->ekphrasis) (0.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->ekphrasis) (1.16.0)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->ekphrasis) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->ekphrasis) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->ekphrasis) (2022.3.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install ekphrasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fed9a046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\ekphrasis\\classes\\tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    #annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",'emphasis', 'censored'},\n",
    "    annotate={\"hashtag\"},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e6334f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# panggil ekphrasis\n",
    "\n",
    "def bersih_data(text):\n",
    "    return \" \".join(text_processor.pre_process_doc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b65fac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi dari AMS 01-03. silakan cek bagaimana saya merubah menjadi fungsi\n",
    "\n",
    "def non_ascii(text):\n",
    "    return text.encode('ascii', 'replace').decode('ascii')\n",
    "\n",
    "def remove_space(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def remove_emoji(text):\n",
    "    return ' '.join(re.sub(\"([x#][A-Za-z0-9]+)\",\" \", text).split())\n",
    "\n",
    "def remove_tab(text):\n",
    "    return text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
    "\n",
    "def remove_tab2(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "def remove_rt(text):\n",
    "    return text.replace('RT',\" \")\n",
    "\n",
    "def remove_mention(text):\n",
    "    return ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "\n",
    "def remove_incomplete_url(text):\n",
    "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "\n",
    "def remove_single_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "def remove_excessive_dot(text):\n",
    "    return text.replace('..',\" \")\n",
    "\n",
    "def change_stripe(text):\n",
    "    return text.replace('-',\" \")\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_single_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "def remove_excessive_dot(text):\n",
    "    return text.replace('..',\" \")\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    remove = string.punctuation\n",
    "    remove = remove.replace(\"_\", \"\") # don't remove hyphens\n",
    "    pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "    return re.sub(pattern, \"\", text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f8e6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hapus untuk <>\n",
    "def remove_number_eks(text):\n",
    "    return text.replace('<number>',\" \")\n",
    "\n",
    "def remove_angka(text):\n",
    "    return re.sub(r\"\\d+\", \"\", text) \n",
    "\n",
    "def remove_URL_eks(text):\n",
    "    return text.replace('URL',\" \").replace('url',\" \")\n",
    "\n",
    "def space_punctuation(text):\n",
    "    return re.sub('(?<! )(?=[.,!?()])|(?<=[.,!?()])(?! )', r' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f396bfb",
   "metadata": {},
   "source": [
    "## Mulai Proses Pembersihan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24af88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "final_string = []\n",
    "s = \"\"\n",
    "for text in df['Tweets'].values:\n",
    "    filteredSentence = []\n",
    "    EachReviewText = \"\"\n",
    "    proc = remove_rt(text)\n",
    "    proc = lower(proc)\n",
    "    proc = change_stripe(proc)\n",
    "    proc = remove_emoji(proc)\n",
    "    proc = remove_tab(proc)\n",
    "    proc = remove_tab2(proc)\n",
    "    proc = non_ascii(proc)\n",
    "    proc = remove_incomplete_url(proc)\n",
    "    proc = remove_excessive_dot(proc)\n",
    "    proc = remove_whitespace_LT(proc)\n",
    "    proc = remove_whitespace_multiple(proc)\n",
    "    proc = remove_single_char(proc)\n",
    "    proc = space_punctuation(proc)\n",
    "    proc = remove_punctuation(proc)\n",
    "    proc = remove_space(proc)\n",
    "    proc = bersih_data(proc)\n",
    "    proc = remove_number_eks(proc)\n",
    "    proc = remove_angka(proc) \n",
    "    proc = remove_URL_eks(proc)\n",
    "    EachReviewText = proc\n",
    "    final_string.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "618f47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"step01\"] = final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c69bd841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@bellaksaragih dagang sate</td>\n",
       "      <td>bellaksaragih dagang sate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>orang-orang terus jadi wibu https://t.co/sDzvf...</td>\n",
       "      <td>orang orang terus jadi wibu cosdzvfpikm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>orang-orang terus melupakan diri\\nmereka sebel...</td>\n",
       "      <td>orang orang terus melupakan diri mereka sebelu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>orang-orang terus jadi abu\\nkita hanyut dalam ...</td>\n",
       "      <td>orang orang terus jadi abu kita hanyut dalam w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cuma malam minggu. dah biasa.</td>\n",
       "      <td>cuma malam minggu dah biasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>BERTEMU DI TEMARAM https://t.co/GkhFfvkOAc</td>\n",
       "      <td>be emu di temaram cogkhffvkoac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>@berlianidris üòÖ</td>\n",
       "      <td>berlianidris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Jangan ajari aku sabar. Dari kecil sampai seka...</td>\n",
       "      <td>jangan ajari aku sabar dari kecil sampai sekar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Di Twitter, cewek masak buat cowoknya, diribut...</td>\n",
       "      <td>di twitter cewek masak buat cowoknya diributin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Tak mengapa sendirian di sepanjang jalan. Mung...</td>\n",
       "      <td>tak mengapa sendirian di sepanjang jalan mungk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Tweets  \\\n",
       "0           0                         @bellaksaragih dagang sate   \n",
       "1           1  orang-orang terus jadi wibu https://t.co/sDzvf...   \n",
       "2           2  orang-orang terus melupakan diri\\nmereka sebel...   \n",
       "3           3  orang-orang terus jadi abu\\nkita hanyut dalam ...   \n",
       "4           4                      cuma malam minggu. dah biasa.   \n",
       "5           5         BERTEMU DI TEMARAM https://t.co/GkhFfvkOAc   \n",
       "6           6                                    @berlianidris üòÖ   \n",
       "7           7  Jangan ajari aku sabar. Dari kecil sampai seka...   \n",
       "8           8  Di Twitter, cewek masak buat cowoknya, diribut...   \n",
       "9           9  Tak mengapa sendirian di sepanjang jalan. Mung...   \n",
       "\n",
       "                                              step01  \n",
       "0                          bellaksaragih dagang sate  \n",
       "1            orang orang terus jadi wibu cosdzvfpikm  \n",
       "2  orang orang terus melupakan diri mereka sebelu...  \n",
       "3  orang orang terus jadi abu kita hanyut dalam w...  \n",
       "4                        cuma malam minggu dah biasa  \n",
       "5                     be emu di temaram cogkhffvkoac  \n",
       "6                                       berlianidris  \n",
       "7  jangan ajari aku sabar dari kecil sampai sekar...  \n",
       "8  di twitter cewek masak buat cowoknya diributin...  \n",
       "9  tak mengapa sendirian di sepanjang jalan mungk...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97917bc",
   "metadata": {},
   "source": [
    "## Hapus Data Kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea2ada8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  200 non-null    int64 \n",
      " 1   Tweets      200 non-null    object\n",
      " 2   step01      200 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "287346ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hapus = df[~df['step01'].str.contains(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35302637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19 entries, 6 to 196\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  19 non-null     int64 \n",
      " 1   Tweets      19 non-null     object\n",
      " 2   step01      19 non-null     object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 608.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_hapus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2d5c57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>@berlianidris üòÖ</td>\n",
       "      <td>berlianidris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>ü§åüèª https://t.co/r8Ry9hwa7r</td>\n",
       "      <td>corryhwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>üôèüèª https://t.co/Huc03qyYxy</td>\n",
       "      <td>cohucqyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>@detikcom üò≠üò≠üò≠</td>\n",
       "      <td>detikcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>pagi.</td>\n",
       "      <td>pagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>@Biruubiu ‚úäüèª</td>\n",
       "      <td>biruubiu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>https://t.co/dGcAEg8myN</td>\n",
       "      <td>codgcaegmyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>@zarryhendrik ü§£</td>\n",
       "      <td>zarryhendrik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>@Adli_DHJ üôèüèª</td>\n",
       "      <td>adli_dhj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>@i_illumine üôèüèª</td>\n",
       "      <td>i_illumine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                      Tweets        step01\n",
       "6             6             @berlianidris üòÖ  berlianidris\n",
       "32           32  ü§åüèª https://t.co/r8Ry9hwa7r     corryhwar\n",
       "33           33  üôèüèª https://t.co/Huc03qyYxy      cohucqyy\n",
       "37           37               @detikcom üò≠üò≠üò≠      detikcom\n",
       "51           51                       pagi.          pagi\n",
       "65           65                @Biruubiu ‚úäüèª      biruubiu\n",
       "68           68     https://t.co/dGcAEg8myN   codgcaegmyn\n",
       "75           75             @zarryhendrik ü§£  zarryhendrik\n",
       "96           96                @Adli_DHJ üôèüèª      adli_dhj\n",
       "115         115              @i_illumine üôèüèª    i_illumine"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hapus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6a59bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[~df.isin(df_hapus)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5b67a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 181 entries, 0 to 199\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  181 non-null    float64\n",
      " 1   Tweets      181 non-null    object \n",
      " 2   step01      181 non-null    object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 5.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b1b1865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@bellaksaragih dagang sate</td>\n",
       "      <td>bellaksaragih dagang sate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>orang-orang terus jadi wibu https://t.co/sDzvf...</td>\n",
       "      <td>orang orang terus jadi wibu cosdzvfpikm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>orang-orang terus melupakan diri\\nmereka sebel...</td>\n",
       "      <td>orang orang terus melupakan diri mereka sebelu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>orang-orang terus jadi abu\\nkita hanyut dalam ...</td>\n",
       "      <td>orang orang terus jadi abu kita hanyut dalam w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>cuma malam minggu. dah biasa.</td>\n",
       "      <td>cuma malam minggu dah biasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>194.0</td>\n",
       "      <td>Di sinar mata, sepanjang hari. Aku merekam set...</td>\n",
       "      <td>di sinar mata sepanjang hari aku merekam setia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195.0</td>\n",
       "      <td>@cynrj Buku senandika</td>\n",
       "      <td>cynrj buku senandika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197.0</td>\n",
       "      <td>Segala yang berlebihan itu nggak baik. Minum a...</td>\n",
       "      <td>segala yang berlebihan itu nggak baik minum ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198.0</td>\n",
       "      <td>Selamat istirahat diri sendiri.</td>\n",
       "      <td>selamat istirahat diri sendiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199.0</td>\n",
       "      <td>Instastori teman-temanku di konser semua.</td>\n",
       "      <td>instastori teman temanku di konser semua</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             Tweets  \\\n",
       "0           0.0                         @bellaksaragih dagang sate   \n",
       "1           1.0  orang-orang terus jadi wibu https://t.co/sDzvf...   \n",
       "2           2.0  orang-orang terus melupakan diri\\nmereka sebel...   \n",
       "3           3.0  orang-orang terus jadi abu\\nkita hanyut dalam ...   \n",
       "4           4.0                      cuma malam minggu. dah biasa.   \n",
       "..          ...                                                ...   \n",
       "194       194.0  Di sinar mata, sepanjang hari. Aku merekam set...   \n",
       "195       195.0                              @cynrj Buku senandika   \n",
       "197       197.0  Segala yang berlebihan itu nggak baik. Minum a...   \n",
       "198       198.0                    Selamat istirahat diri sendiri.   \n",
       "199       199.0          Instastori teman-temanku di konser semua.   \n",
       "\n",
       "                                                step01  \n",
       "0                            bellaksaragih dagang sate  \n",
       "1              orang orang terus jadi wibu cosdzvfpikm  \n",
       "2    orang orang terus melupakan diri mereka sebelu...  \n",
       "3    orang orang terus jadi abu kita hanyut dalam w...  \n",
       "4                          cuma malam minggu dah biasa  \n",
       "..                                                 ...  \n",
       "194  di sinar mata sepanjang hari aku merekam setia...  \n",
       "195                               cynrj buku senandika  \n",
       "197  segala yang berlebihan itu nggak baik minum ai...  \n",
       "198                     selamat istirahat diri sendiri  \n",
       "199           instastori teman temanku di konser semua  \n",
       "\n",
       "[181 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9903e70",
   "metadata": {},
   "source": [
    "## Normalisasi Kata Slang Menjadi Baku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3258bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# token\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd0abc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize_wrapper(text):\n",
    "  return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6023d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['tokens'] = df[\"step01\"].apply(word_tokenize_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52aeb57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>step01</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@bellaksaragih dagang sate</td>\n",
       "      <td>bellaksaragih dagang sate</td>\n",
       "      <td>[bellaksaragih, dagang, sate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>orang-orang terus jadi wibu https://t.co/sDzvf...</td>\n",
       "      <td>orang orang terus jadi wibu cosdzvfpikm</td>\n",
       "      <td>[orang, orang, terus, jadi, wibu, cosdzvfpikm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>orang-orang terus melupakan diri\\nmereka sebel...</td>\n",
       "      <td>orang orang terus melupakan diri mereka sebelu...</td>\n",
       "      <td>[orang, orang, terus, melupakan, diri, mereka,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>orang-orang terus jadi abu\\nkita hanyut dalam ...</td>\n",
       "      <td>orang orang terus jadi abu kita hanyut dalam w...</td>\n",
       "      <td>[orang, orang, terus, jadi, abu, kita, hanyut,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>cuma malam minggu. dah biasa.</td>\n",
       "      <td>cuma malam minggu dah biasa</td>\n",
       "      <td>[cuma, malam, minggu, dah, biasa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>BERTEMU DI TEMARAM https://t.co/GkhFfvkOAc</td>\n",
       "      <td>be emu di temaram cogkhffvkoac</td>\n",
       "      <td>[be, emu, di, temaram, cogkhffvkoac]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Jangan ajari aku sabar. Dari kecil sampai seka...</td>\n",
       "      <td>jangan ajari aku sabar dari kecil sampai sekar...</td>\n",
       "      <td>[jangan, ajari, aku, sabar, dari, kecil, sampa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Di Twitter, cewek masak buat cowoknya, diribut...</td>\n",
       "      <td>di twitter cewek masak buat cowoknya diributin...</td>\n",
       "      <td>[di, twitter, cewek, masak, buat, cowoknya, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Tak mengapa sendirian di sepanjang jalan. Mung...</td>\n",
       "      <td>tak mengapa sendirian di sepanjang jalan mungk...</td>\n",
       "      <td>[tak, mengapa, sendirian, di, sepanjang, jalan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Jam-jam rawan mikir: buat apa ya gue buru mati...</td>\n",
       "      <td>jam jam rawan mikir buat apa ya gue buru mati ...</td>\n",
       "      <td>[jam, jam, rawan, mikir, buat, apa, ya, gue, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                             Tweets  \\\n",
       "0          0.0                         @bellaksaragih dagang sate   \n",
       "1          1.0  orang-orang terus jadi wibu https://t.co/sDzvf...   \n",
       "2          2.0  orang-orang terus melupakan diri\\nmereka sebel...   \n",
       "3          3.0  orang-orang terus jadi abu\\nkita hanyut dalam ...   \n",
       "4          4.0                      cuma malam minggu. dah biasa.   \n",
       "5          5.0         BERTEMU DI TEMARAM https://t.co/GkhFfvkOAc   \n",
       "7          7.0  Jangan ajari aku sabar. Dari kecil sampai seka...   \n",
       "8          8.0  Di Twitter, cewek masak buat cowoknya, diribut...   \n",
       "9          9.0  Tak mengapa sendirian di sepanjang jalan. Mung...   \n",
       "10        10.0  Jam-jam rawan mikir: buat apa ya gue buru mati...   \n",
       "\n",
       "                                               step01  \\\n",
       "0                           bellaksaragih dagang sate   \n",
       "1             orang orang terus jadi wibu cosdzvfpikm   \n",
       "2   orang orang terus melupakan diri mereka sebelu...   \n",
       "3   orang orang terus jadi abu kita hanyut dalam w...   \n",
       "4                         cuma malam minggu dah biasa   \n",
       "5                      be emu di temaram cogkhffvkoac   \n",
       "7   jangan ajari aku sabar dari kecil sampai sekar...   \n",
       "8   di twitter cewek masak buat cowoknya diributin...   \n",
       "9   tak mengapa sendirian di sepanjang jalan mungk...   \n",
       "10  jam jam rawan mikir buat apa ya gue buru mati ...   \n",
       "\n",
       "                                               tokens  \n",
       "0                       [bellaksaragih, dagang, sate]  \n",
       "1      [orang, orang, terus, jadi, wibu, cosdzvfpikm]  \n",
       "2   [orang, orang, terus, melupakan, diri, mereka,...  \n",
       "3   [orang, orang, terus, jadi, abu, kita, hanyut,...  \n",
       "4                   [cuma, malam, minggu, dah, biasa]  \n",
       "5                [be, emu, di, temaram, cogkhffvkoac]  \n",
       "7   [jangan, ajari, aku, sabar, dari, kecil, sampa...  \n",
       "8   [di, twitter, cewek, masak, buat, cowoknya, di...  \n",
       "9   [tak, mengapa, sendirian, di, sepanjang, jalan...  \n",
       "10  [jam, jam, rawan, mikir, buat, apa, ya, gue, b...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67179288",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_word = pd.read_csv('kamus_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "496428f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_word_dict = {}\n",
    "\n",
    "for index, row in normalized_word.iterrows():\n",
    "    if row[0] not in normalized_word_dict:\n",
    "        normalized_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalized_term(document):\n",
    "    return [normalized_word_dict[term] if term in normalized_word_dict else term for term in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d372c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['final_tokens'] = df_new['tokens'].apply(normalized_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af91a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "final_string_tokens = []\n",
    "for text in df_new['final_tokens'].values:\n",
    "    EachReviewText = \"\"\n",
    "    EachReviewText = ' '.join(text)\n",
    "    final_string_tokens.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c2bacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"step02\"] = final_string_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d31d1113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>step01</th>\n",
       "      <th>tokens</th>\n",
       "      <th>final_tokens</th>\n",
       "      <th>step02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@bellaksaragih dagang sate</td>\n",
       "      <td>bellaksaragih dagang sate</td>\n",
       "      <td>[bellaksaragih, dagang, sate]</td>\n",
       "      <td>[bellaksaragih, dagang, sate]</td>\n",
       "      <td>bellaksaragih dagang sate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>orang-orang terus jadi wibu https://t.co/sDzvf...</td>\n",
       "      <td>orang orang terus jadi wibu cosdzvfpikm</td>\n",
       "      <td>[orang, orang, terus, jadi, wibu, cosdzvfpikm]</td>\n",
       "      <td>[orang, orang, terus, jadi, wibu, cosdzvfpikm]</td>\n",
       "      <td>orang orang terus jadi wibu cosdzvfpikm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>orang-orang terus melupakan diri\\nmereka sebel...</td>\n",
       "      <td>orang orang terus melupakan diri mereka sebelu...</td>\n",
       "      <td>[orang, orang, terus, melupakan, diri, mereka,...</td>\n",
       "      <td>[orang, orang, terus, melupakan, diri, mereka,...</td>\n",
       "      <td>orang orang terus melupakan diri mereka sebelu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>orang-orang terus jadi abu\\nkita hanyut dalam ...</td>\n",
       "      <td>orang orang terus jadi abu kita hanyut dalam w...</td>\n",
       "      <td>[orang, orang, terus, jadi, abu, kita, hanyut,...</td>\n",
       "      <td>[orang, orang, terus, jadi, abu, kita, hanyut,...</td>\n",
       "      <td>orang orang terus jadi abu kita hanyut dalam w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>cuma malam minggu. dah biasa.</td>\n",
       "      <td>cuma malam minggu dah biasa</td>\n",
       "      <td>[cuma, malam, minggu, dah, biasa]</td>\n",
       "      <td>[cuma, malam, minggu, dah, biasa]</td>\n",
       "      <td>cuma malam minggu dah biasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>BERTEMU DI TEMARAM https://t.co/GkhFfvkOAc</td>\n",
       "      <td>be emu di temaram cogkhffvkoac</td>\n",
       "      <td>[be, emu, di, temaram, cogkhffvkoac]</td>\n",
       "      <td>[be, emu, di, temaram, cogkhffvkoac]</td>\n",
       "      <td>be emu di temaram cogkhffvkoac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Jangan ajari aku sabar. Dari kecil sampai seka...</td>\n",
       "      <td>jangan ajari aku sabar dari kecil sampai sekar...</td>\n",
       "      <td>[jangan, ajari, aku, sabar, dari, kecil, sampa...</td>\n",
       "      <td>[jangan, ajari, aku, sabar, dari, kecil, sampa...</td>\n",
       "      <td>jangan ajari aku sabar dari kecil sampai sekar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Di Twitter, cewek masak buat cowoknya, diribut...</td>\n",
       "      <td>di twitter cewek masak buat cowoknya diributin...</td>\n",
       "      <td>[di, twitter, cewek, masak, buat, cowoknya, di...</td>\n",
       "      <td>[di, twitter, cewek, masak, buat, cowoknya, di...</td>\n",
       "      <td>di twitter cewek masak buat cowoknya diributin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Tak mengapa sendirian di sepanjang jalan. Mung...</td>\n",
       "      <td>tak mengapa sendirian di sepanjang jalan mungk...</td>\n",
       "      <td>[tak, mengapa, sendirian, di, sepanjang, jalan...</td>\n",
       "      <td>[tak, mengapa, sendirian, di, sepanjang, jalan...</td>\n",
       "      <td>tak mengapa sendirian di sepanjang jalan mungk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Jam-jam rawan mikir: buat apa ya gue buru mati...</td>\n",
       "      <td>jam jam rawan mikir buat apa ya gue buru mati ...</td>\n",
       "      <td>[jam, jam, rawan, mikir, buat, apa, ya, gue, b...</td>\n",
       "      <td>[jam, jam, rawan, mikir, buat, apa, ya, gue, b...</td>\n",
       "      <td>jam jam rawan mikir buat apa ya gue buru mati ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                             Tweets  \\\n",
       "0          0.0                         @bellaksaragih dagang sate   \n",
       "1          1.0  orang-orang terus jadi wibu https://t.co/sDzvf...   \n",
       "2          2.0  orang-orang terus melupakan diri\\nmereka sebel...   \n",
       "3          3.0  orang-orang terus jadi abu\\nkita hanyut dalam ...   \n",
       "4          4.0                      cuma malam minggu. dah biasa.   \n",
       "5          5.0         BERTEMU DI TEMARAM https://t.co/GkhFfvkOAc   \n",
       "7          7.0  Jangan ajari aku sabar. Dari kecil sampai seka...   \n",
       "8          8.0  Di Twitter, cewek masak buat cowoknya, diribut...   \n",
       "9          9.0  Tak mengapa sendirian di sepanjang jalan. Mung...   \n",
       "10        10.0  Jam-jam rawan mikir: buat apa ya gue buru mati...   \n",
       "\n",
       "                                               step01  \\\n",
       "0                           bellaksaragih dagang sate   \n",
       "1             orang orang terus jadi wibu cosdzvfpikm   \n",
       "2   orang orang terus melupakan diri mereka sebelu...   \n",
       "3   orang orang terus jadi abu kita hanyut dalam w...   \n",
       "4                         cuma malam minggu dah biasa   \n",
       "5                      be emu di temaram cogkhffvkoac   \n",
       "7   jangan ajari aku sabar dari kecil sampai sekar...   \n",
       "8   di twitter cewek masak buat cowoknya diributin...   \n",
       "9   tak mengapa sendirian di sepanjang jalan mungk...   \n",
       "10  jam jam rawan mikir buat apa ya gue buru mati ...   \n",
       "\n",
       "                                               tokens  \\\n",
       "0                       [bellaksaragih, dagang, sate]   \n",
       "1      [orang, orang, terus, jadi, wibu, cosdzvfpikm]   \n",
       "2   [orang, orang, terus, melupakan, diri, mereka,...   \n",
       "3   [orang, orang, terus, jadi, abu, kita, hanyut,...   \n",
       "4                   [cuma, malam, minggu, dah, biasa]   \n",
       "5                [be, emu, di, temaram, cogkhffvkoac]   \n",
       "7   [jangan, ajari, aku, sabar, dari, kecil, sampa...   \n",
       "8   [di, twitter, cewek, masak, buat, cowoknya, di...   \n",
       "9   [tak, mengapa, sendirian, di, sepanjang, jalan...   \n",
       "10  [jam, jam, rawan, mikir, buat, apa, ya, gue, b...   \n",
       "\n",
       "                                         final_tokens  \\\n",
       "0                       [bellaksaragih, dagang, sate]   \n",
       "1      [orang, orang, terus, jadi, wibu, cosdzvfpikm]   \n",
       "2   [orang, orang, terus, melupakan, diri, mereka,...   \n",
       "3   [orang, orang, terus, jadi, abu, kita, hanyut,...   \n",
       "4                   [cuma, malam, minggu, dah, biasa]   \n",
       "5                [be, emu, di, temaram, cogkhffvkoac]   \n",
       "7   [jangan, ajari, aku, sabar, dari, kecil, sampa...   \n",
       "8   [di, twitter, cewek, masak, buat, cowoknya, di...   \n",
       "9   [tak, mengapa, sendirian, di, sepanjang, jalan...   \n",
       "10  [jam, jam, rawan, mikir, buat, apa, ya, gue, b...   \n",
       "\n",
       "                                               step02  \n",
       "0                           bellaksaragih dagang sate  \n",
       "1             orang orang terus jadi wibu cosdzvfpikm  \n",
       "2   orang orang terus melupakan diri mereka sebelu...  \n",
       "3   orang orang terus jadi abu kita hanyut dalam w...  \n",
       "4                         cuma malam minggu dah biasa  \n",
       "5                      be emu di temaram cogkhffvkoac  \n",
       "7   jangan ajari aku sabar dari kecil sampai sekar...  \n",
       "8   di twitter cewek masak buat cowoknya diributin...  \n",
       "9   tak mengapa sendirian di sepanjang jalan mungk...  \n",
       "10  jam jam rawan mikir buat apa ya gue buru mati ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f39e0",
   "metadata": {},
   "source": [
    "## Simpan Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55888a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('clean_dataset_dsuperboy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5719644c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
